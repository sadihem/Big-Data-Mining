{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported Spark Modules\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.clustering import KMeans\n",
    "from pyspark.mllib.feature import StandardScaler\n",
    "print (\"Successfully imported Spark Modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from numpy import array\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_interaction(line):\n",
    "    \"\"\"\n",
    "    Parses a network data interaction.\n",
    "    \"\"\"\n",
    "    line_split = line.split(\",\")\n",
    "    clean_line_split = [line_split[0]]+line_split[4:-1]\n",
    "    return (line_split[-1], array([float(x) for x in clean_line_split]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance(a, b):\n",
    "    \"\"\"\n",
    "    Calculates the euclidean distance between two numeric RDDs\n",
    "    \"\"\"\n",
    "    return sqrt(\n",
    "        a.zip(b)\n",
    "        .map(lambda x: (x[0]-x[1]))\n",
    "        .map(lambda x: x*x)\n",
    "        .reduce(lambda a,b: a+b)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist_to_centroid(datum, clusters):\n",
    "    \"\"\"\n",
    "    Determines the distance of a point to its cluster centroid\n",
    "    \"\"\"\n",
    "    cluster = clusters.predict(datum)\n",
    "    centroid = clusters.centers[cluster]\n",
    "    return sqrt(sum([x**2 for x in (centroid - datum)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clustering_score(data, k):\n",
    "    clusters = KMeans.train(data, k, maxIterations=10, runs=5, initializationMode=\"random\")\n",
    "    result = (k, clusters, data.map(lambda datum: dist_to_centroid(datum, clusters)).mean())\n",
    "    print \"Clustering score for k=%(k)d is %(score)f\" % {\"k\": k, \"score\": result[2]}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RAW data...\n"
     ]
    }
   ],
   "source": [
    "max_k = 10;\n",
    "data_file='/Users/v33/Dropbox/DataMiningCOSC526/2016/Datasets/KDD-NetworkAnomalies/kddcup.data_10_percent';\n",
    "\n",
    "# load raw data\n",
    "print \"Loading RAW data...\"\n",
    "raw_data = sc.textFile(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting all different labels\n",
      "smurf. 280790\n",
      "neptune. 107201\n",
      "normal. 97278\n",
      "back. 2203\n",
      "satan. 1589\n",
      "ipsweep. 1247\n",
      "portsweep. 1040\n",
      "warezclient. 1020\n",
      "teardrop. 979\n",
      "pod. 264\n",
      "nmap. 231\n",
      "guess_passwd. 53\n",
      "buffer_overflow. 30\n",
      "land. 21\n",
      "warezmaster. 20\n",
      "imap. 12\n",
      "rootkit. 10\n",
      "loadmodule. 9\n",
      "ftp_write. 8\n",
      "multihop. 7\n",
      "phf. 4\n",
      "perl. 3\n",
      "spy. 2\n"
     ]
    }
   ],
   "source": [
    "# count by all different labels and print them decreasingly\n",
    "print \"Counting all different labels\"\n",
    "labels = raw_data.map(lambda line: line.strip().split(\",\")[-1])\n",
    "label_counts = labels.countByValue()\n",
    "sorted_labels = OrderedDict(sorted(label_counts.items(), key=lambda t: t[1], reverse=True))\n",
    "for label, count in sorted_labels.items():\n",
    "    print label, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing dataset...\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for clustering input\n",
    "# the data contains non-numeric features, we want to exclude them since\n",
    "# k-means works with numeric features. These are the first three and the last\n",
    "# column in each data row\n",
    "print \"Parsing dataset...\"\n",
    "parsed_data = raw_data.map(parse_interaction)\n",
    "parsed_data_values = parsed_data.values().cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating total in within cluster distance for different k values (10 to 10):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/v33/Install/spark-1.6.0/python/pyspark/mllib/clustering.py:176: UserWarning: Support for runs is deprecated in 1.6.0. This param will have no effect in 1.7.0.\n",
      "  \"Support for runs is deprecated in 1.6.0. This param will have no effect in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering score for k=10 is 782.674504\n"
     ]
    }
   ],
   "source": [
    "# Evaluate values of k from 5 to 40\n",
    "print \"Calculating total in within cluster distance for different k values (10 to %(max_k)d):\" % {\"max_k\": max_k}\n",
    "scores = map(lambda k: clustering_score(parsed_data_values, k), range(10,max_k+1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
